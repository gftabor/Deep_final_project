{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import tarfile\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking what kind of system you are using\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  from google.colab import files\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "try:\n",
    "    hostname = !hostname\n",
    "    if 'lab' in hostname[0] and '.eng.utah.edu' in hostname[0]:\n",
    "        IN_CADE = True\n",
    "    else:\n",
    "        IN_CADE = False\n",
    "except:\n",
    "    IN_CADE = False\n",
    "\n",
    "assert(not IN_CADE or not IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gpu_to_use(minimum_memory_mb = 3800):\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader\n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        if free_memory>minimum_memory_mb-500:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' +str(minimum_memory_mb) + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-500)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the gpu that will be used, testing if it has enough available memory, and reserving the needed memory\n",
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_bbox(size, bbox):\n",
    "    bbox = bbox.astype(np.float32)\n",
    "    bbox[:,0] /= size[0]\n",
    "    bbox[:,1] /= size[1]\n",
    "    bbox[:,2] += 1\n",
    "    bbox[:,2] /= size[0]\n",
    "    bbox[:,3] += 1\n",
    "    bbox[:,3] /= size[1]\n",
    "    return bbox\n",
    "def bbox_transform(ex_rois, gt_rois):\n",
    "    ex_widths = ex_rois[:,2] - ex_rois[:,0] + 1.0\n",
    "    ex_heights = ex_rois[:,3] - ex_rois[:,1] + 1.0\n",
    "    ex_ctr_x = ex_rois[:,0] + 0.5 * ex_widths\n",
    "    ex_ctr_y = ex_rois[:,1] + 0.5 * ex_heights\n",
    "\n",
    "    gt_widths = gt_rois[:,2] - gt_rois[:,0] + 1.0\n",
    "    gt_heights = gt_rois[:,3] - gt_rois[:,1] + 1.0\n",
    "    gt_ctr_x = gt_rois[:,0] + 0.5 * gt_widths\n",
    "    gt_ctr_y = gt_rois[:,1] + 0.5 * gt_heights\n",
    "\n",
    "    targets_dx = (gt_ctr_x - ex_ctr_x) / ex_widths\n",
    "    targets_dy = (gt_ctr_y - ex_ctr_y) / ex_heights\n",
    "    targets_dw = np.log(gt_widths / ex_widths)\n",
    "    targets_dh = np.log(gt_heights / ex_heights)\n",
    "\n",
    "    targets = np.array([targets_dx, targets_dy, targets_dw, targets_dh]).T\n",
    "    return targets\n",
    "def calc_ious(ex_rois, gt_rois):\n",
    "    ex_area = (1. + ex_rois[:,2] - ex_rois[:,0]) * (1. + ex_rois[:,3] - ex_rois[:,1])\n",
    "    gt_area = (1. + gt_rois[:,2] - gt_rois[:,0]) * (1. + gt_rois[:,3] - gt_rois[:,1])\n",
    "    area_sum = ex_area.reshape((-1, 1)) + gt_area.reshape((1, -1))\n",
    "\n",
    "    lb = np.maximum(ex_rois[:,0].reshape((-1, 1)), gt_rois[:,0].reshape((1, -1)))\n",
    "    rb = np.minimum(ex_rois[:,2].reshape((-1, 1)), gt_rois[:,2].reshape((1, -1)))\n",
    "    tb = np.maximum(ex_rois[:,1].reshape((-1, 1)), gt_rois[:,1].reshape((1, -1)))\n",
    "    ub = np.minimum(ex_rois[:,3].reshape((-1, 1)), gt_rois[:,3].reshape((1, -1)))\n",
    "\n",
    "    width = np.maximum(1. + rb - lb, 0.)\n",
    "    height = np.maximum(1. + ub - tb, 0.)\n",
    "    area_i = width * height\n",
    "    area_u = area_sum - area_i\n",
    "    ious = area_i / area_u\n",
    "    return ious\n",
    "def reg_to_bbox(img_size, reg, box):\n",
    "    img_width, img_height = img_size\n",
    "    bbox_width = box[:,2] - box[:,0] + 1.0\n",
    "    bbox_height = box[:,3] - box[:,1] + 1.0\n",
    "    bbox_ctr_x = box[:,0] + 0.5 * bbox_width\n",
    "    bbox_ctr_y = box[:,1] + 0.5 * bbox_height\n",
    "\n",
    "    bbox_width = bbox_width[:,np.newaxis]\n",
    "    bbox_height = bbox_height[:,np.newaxis]\n",
    "    bbox_ctr_x = bbox_ctr_x[:,np.newaxis]\n",
    "    bbox_ctr_y = bbox_ctr_y[:,np.newaxis]\n",
    "\n",
    "    out_ctr_x = reg[:,:,0] * bbox_width + bbox_ctr_x\n",
    "    out_ctr_y = reg[:,:,1] * bbox_height + bbox_ctr_y\n",
    "\n",
    "    out_width = bbox_width * np.exp(reg[:,:,2])\n",
    "    out_height = bbox_height * np.exp(reg[:,:,3])\n",
    "\n",
    "    return np.array([\n",
    "        np.maximum(0, out_ctr_x - 0.5 * out_width),\n",
    "        np.maximum(0, out_ctr_y - 0.5 * out_height),\n",
    "        np.minimum(img_width, out_ctr_x + 0.5 * out_width),\n",
    "        np.minimum(img_height, out_ctr_y + 0.5 * out_height)\n",
    "    ]).transpose([1, 2, 0])\n",
    "\n",
    "def non_maximum_suppression(sc, bboxs, iou_threshold=0.7, score_threshold=0.6):\n",
    "    nroi = sc.shape[0]\n",
    "    idx = np.argsort(sc)[::-1]\n",
    "    rb = 0\n",
    "    while rb < nroi and sc[idx[rb]] >= score_threshold:\n",
    "        rb += 1\n",
    "    if rb == 0:\n",
    "        return []\n",
    "    idx = idx[:rb]\n",
    "    sc = sc[idx]\n",
    "    bboxs = bboxs[idx,:]\n",
    "    ious = calc_ious(bboxs, bboxs)\n",
    "\n",
    "    res = []\n",
    "    for i in range(rb):\n",
    "        if i == 0 or ious[i, :i].max() < iou_threshold:\n",
    "            res.append(bboxs[i])\n",
    "\n",
    "    return res\n",
    "\n",
    "def plot (name, title, legendx, legendy, x, y, n_epoch, frame_size = 256,labelx = 'Epoch', labely = 'Loss'):\n",
    "    i = 0\n",
    "    x = np.array(x).flatten('F')\n",
    "    y = np.array(y).flatten('F')\n",
    "    framex = []\n",
    "    framey = []\n",
    "    \n",
    "    while i*frame_size < len(x):\n",
    "        framex.append(np.mean(x[i*frame_size:min(len(x),(i+1)*frame_size)]))\n",
    "        framey.append(np.mean(y[i*frame_size:min(len(y),(i+1)*frame_size)]))\n",
    "        i += 1\n",
    "    \n",
    "    a = np.arange(0,len(x),len(x)/len(framex))\n",
    "    b = a/len(y)*n_epoch\n",
    "    a = a/len(x)*n_epoch\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(a,framex)\n",
    "    plt.plot(b,framey)\n",
    "    plt.xlabel(labelx)\n",
    "    plt.ylabel(labely)\n",
    "    plt.title(title)\n",
    "    plt.legend([legendx,legendy])\n",
    "    plt.savefig(name,dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowROIPool(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(output_size)\n",
    "        self.size = output_size\n",
    "\n",
    "    def forward(self, images, rois, roi_idx):\n",
    "        n = rois.shape[0]\n",
    "        h = images.size(2)\n",
    "        w = images.size(3)\n",
    "        x1 = rois[:,0]\n",
    "        y1 = rois[:,1]\n",
    "        x2 = rois[:,2]\n",
    "        y2 = rois[:,3]\n",
    "\n",
    "        x1 = np.floor(x1 * w).astype(int)\n",
    "        x2 = np.ceil(x2 * w).astype(int)\n",
    "        y1 = np.floor(y1 * h).astype(int)\n",
    "        y2 = np.ceil(y2 * h).astype(int)\n",
    "        \n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            img = images[roi_idx[i]].unsqueeze(0)\n",
    "            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]]\n",
    "            img = self.maxpool(img)\n",
    "            res.append(img)\n",
    "        res = torch.cat(res, dim=0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        rawnet = torchvision.models.vgg16_bn(pretrained=True)\n",
    "        self.seq = nn.Sequential(*list(rawnet.features.children())[:-1])\n",
    "        self.roipool = SlowROIPool(output_size=(7, 7))\n",
    "        self.feature = nn.Sequential(*list(rawnet.classifier.children())[:-1])\n",
    "\n",
    "        _x = Variable(torch.Tensor(1, 3, 224, 224))\n",
    "        _r = np.array([[0., 0., 1., 1.]])\n",
    "        _ri = np.array([0])\n",
    "        _x = self.feature(self.roipool(self.seq(_x), _r, _ri).view(1, -1))\n",
    "        feature_dim = _x.size(1)\n",
    "        self.cls_score = nn.Linear(feature_dim, N_CLASS+1)\n",
    "        self.bbox = nn.Linear(feature_dim, 4*(N_CLASS+1))\n",
    "        \n",
    "        self.cel = nn.CrossEntropyLoss()\n",
    "        self.sl1 = nn.SmoothL1Loss()\n",
    "\n",
    "    def forward(self, inp, rois, ridx):\n",
    "        res = inp\n",
    "        res = self.seq(res)\n",
    "        res = self.roipool(res, rois, ridx)\n",
    "        res = res.detach()\n",
    "        res = res.view(res.size(0), -1)\n",
    "        feat = self.feature(res)\n",
    "\n",
    "        cls_score = self.cls_score(feat)\n",
    "        bbox = self.bbox(feat).view(-1, N_CLASS+1, 4)\n",
    "        return cls_score, bbox\n",
    "\n",
    "    def calc_loss(self, probs, bbox, labels, gt_bbox):\n",
    "        loss_sc = self.cel(probs, labels)\n",
    "        lbl = labels.view(-1, 1, 1).expand(labels.size(0), 1, 4)\n",
    "        mask = (labels != 0).float().view(-1, 1).expand(labels.size(0), 4)\n",
    "        loss_loc = self.sl1(bbox.gather(1, lbl).squeeze(1) * mask, gt_bbox * mask)\n",
    "        lmb = 1.0\n",
    "        loss = loss_sc + lmb * loss_loc\n",
    "        return loss, loss_sc, loss_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(img, img_size, rois, orig_rois):\n",
    "    nroi = rois.shape[0]\n",
    "    ridx = np.zeros(nroi).astype(int)\n",
    "    sc, tbbox = rcnn(img, rois, ridx)\n",
    "    sc = nn.functional.softmax(sc)\n",
    "    sc = sc.data.cpu().numpy()\n",
    "    tbbox = tbbox.data.cpu().numpy()\n",
    "    bboxs = reg_to_bbox(img_size, tbbox, orig_rois)\n",
    "\n",
    "    res_bbox = []\n",
    "    res_cls = []\n",
    "\n",
    "    for c in range(1, N_CLASS+1):\n",
    "        c_sc = sc[:,c]\n",
    "        c_bboxs = bboxs[:,c,:]\n",
    "\n",
    "        boxes = non_maximum_suppression(c_sc, c_bboxs, iou_threshold=0.3, score_threshold=0.6)\n",
    "        res_bbox.extend(boxes)\n",
    "        res_cls.extend([c] * len(boxes))\n",
    "\n",
    "    if len(res_cls) == 0:\n",
    "        for c in range(1, N_CLASS+1):\n",
    "            c_sc = sc[:,c]\n",
    "            c_bboxs = bboxs[:,c,:]\n",
    "\n",
    "            boxes = non_maximum_suppression(c_sc, c_bboxs, iou_threshold=0.3, score_threshold=0.3)\n",
    "            res_bbox.extend(boxes)\n",
    "            res_cls.extend([c] * len(boxes))\n",
    "        res_bbox = res_bbox[:1]\n",
    "        res_cls = res_cls[:1]\n",
    "\n",
    "    print(res_cls)\n",
    "\n",
    "    return np.array(res_bbox), np.array(res_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch():\n",
    "    Nimg = test_imgs.size(0)\n",
    "    Nc = Nimg\n",
    "\n",
    "    perm = np.random.permutation(Nimg)[:Nc]\n",
    "\n",
    "    bbox_preds = []\n",
    "    bbox_cls = []\n",
    "\n",
    "    for i in range(Nimg):\n",
    "        bbox_preds.append(np.ndarray((0, 4)))\n",
    "        bbox_cls.append(np.ndarray((0, 1)))\n",
    "\n",
    "    for i in range(Nc):\n",
    "        pi = perm[i]\n",
    "        img = Variable(test_imgs[pi:pi+1], volatile=True)\n",
    "        ridx = []\n",
    "        glo_ids = []\n",
    "\n",
    "        info = test_img_info[pi]\n",
    "        img_size = info['img_size']\n",
    "        idxs = info['idxs']\n",
    "\n",
    "        idxs = np.array(idxs)\n",
    "        rois = test_roi[idxs]\n",
    "        orig_rois = test_orig_roi[idxs]\n",
    "\n",
    "        res_bbox, res_cls = test_image(img, img_size, rois, orig_rois)\n",
    "        bbox_preds[pi] = res_bbox\n",
    "        bbox_cls[pi] = res_cls\n",
    "\n",
    "    evaluate.evaluate(bbox_preds, bbox_cls)\n",
    "\n",
    "    print('Test complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to location of root directory\n",
    "root = \"/hdd/\"\n",
    "folders = [\"pringles_1k_1554610789151371002\",\n",
    "           \"black_decker_1k_1554675460418814897\",\n",
    "          \"lego_toy_1k_1554674193206299066\",\n",
    "          \"pringles_1k_1554677386797606945\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "class ourDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        \n",
    "        labelFileName = folder + \"/labels.txt\"\n",
    "        file = open(labelFileName,\"r\")\n",
    "        \n",
    "        lines = file.readlines()\n",
    "        self.count = len(lines)\n",
    "        self.examples = []\n",
    "        for line in lines:\n",
    "            array = line.split(\" \")\n",
    "            example = [array[0],array[1],\n",
    "                       int(array[2]),int(array[3]),\n",
    "                       int(array[4]),int(array[5])]\n",
    "            #print(example)\n",
    "            self.examples.append(example)\n",
    "            \n",
    "        self.image_folder = folder + \"/images/\"\n",
    "        self.transformations = \\\n",
    "            transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # stuff\n",
    "        \n",
    "        single_image_name = self.image_folder +self.examples[index][0]\n",
    "        img_as_img = Image.open(single_image_name)\n",
    "        img = self.transformations(img_as_img) \n",
    "        label = 1\n",
    "        \n",
    "        \n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count # of how many data(images?) you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "validation_split = .2\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "datasets = []\n",
    "for f in folders:\n",
    "    folder = root + f\n",
    "    datasets.append(ourDataset(folder))\n",
    "dataset = torch.utils.data.ConcatDataset(datasets)\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 20\n",
    "model = RCNN().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
