{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking what kind of system you are using\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  from google.colab import files\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "try:\n",
    "    hostname = !hostname\n",
    "    if 'lab' in hostname[0] and '.eng.utah.edu' in hostname[0]:\n",
    "        IN_CADE = True\n",
    "    else:\n",
    "        IN_CADE = False\n",
    "except:\n",
    "    IN_CADE = False\n",
    "\n",
    "assert(not IN_CADE or not IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gpu_to_use(minimum_memory_mb = 3800):\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader\n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        if free_memory>minimum_memory_mb-500:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' +str(minimum_memory_mb) + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-500)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the gpu that will be used, testing if it has enough available memory, and reserving the needed memory\n",
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing for RPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "image = torch.zeros((1, 3, 800, 800)).float()\n",
    "\n",
    "bbox = torch.FloatTensor([[20, 30, 400, 500], [300, 400, 500, 600]]) # [y1, x1, y2, x2] format\n",
    "labels = torch.LongTensor([6, 8]) # 0 represents background\n",
    "sub_sample = 16\n",
    "\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "dummy_img = torch.zeros((1, 3, 800, 800)).float()\n",
    "print(dummy_img.shape)\n",
    "#Out: torch.Size([1, 3, 800, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "fe = list(model.features)\n",
    "\n",
    "print(fe) # length is 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_features = []\n",
    "fee = []\n",
    "k = dummy_img.clone()\n",
    "for i in fe:\n",
    "    k = i(k)\n",
    "    if k.size()[2] < 800//16:\n",
    "        break\n",
    "    fee.append(i)\n",
    "    req_features.append(i)\n",
    "    out_channels = k.size()[1]\n",
    "print(len(req_features)) #30\n",
    "print(len(fee))\n",
    "print(out_channels) # 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_fe_extractor = torch.nn.Sequential(*req_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_map = faster_rcnn_fe_extractor(image)\n",
    "print(out_map.size())\n",
    "#Out: torch.Size([1, 512, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ratio = [0.5, 1, 2]\n",
    "anchor_scales = [8, 16, 32]\n",
    "\n",
    "anchor_base = np.zeros((len(ratio) * len(anchor_scales), 4), dtype=np.float32)\n",
    "#anchor_base = np.zeros((len(ratios) * len(scales), 4), dtype=np.float32)\n",
    "\n",
    "print(anchor_base)\n",
    "\n",
    "#Out:\n",
    "# array([[0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0.]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr_y = sub_sample / 2.\n",
    "ctr_x = sub_sample / 2.\n",
    "\n",
    "print(ctr_y, ctr_x)\n",
    "# Out: (8, 8)\n",
    "for i in range(len(ratio)):\n",
    "  for j in range(len(anchor_scales)):\n",
    "    h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "    w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratio[i])\n",
    "\n",
    "    index = i * len(anchor_scales) + j\n",
    "\n",
    "    anchor_base[index, 0] = ctr_y - h / 2.\n",
    "    anchor_base[index, 1] = ctr_x - w / 2.\n",
    "    anchor_base[index, 2] = ctr_y + h / 2.\n",
    "    anchor_base[index, 3] = ctr_x + w / 2.\n",
    "\n",
    "print(anchor_base)\n",
    "#Out:\n",
    "# array([[ -37.254833,  -82.50967 ,   53.254833,   98.50967 ],\n",
    "#        [ -82.50967 , -173.01933 ,   98.50967 ,  189.01933 ],\n",
    "#        [-173.01933 , -354.03867 ,  189.01933 ,  370.03867 ],\n",
    "#        [ -56.      ,  -56.      ,   72.      ,   72.      ],\n",
    "#        [-120.      , -120.      ,  136.      ,  136.      ],\n",
    "#        [-248.      , -248.      ,  264.      ,  264.      ],\n",
    "#        [ -82.50967 ,  -37.254833,   98.50967 ,   53.254833],\n",
    "#        [-173.01933 ,  -82.50967 ,  189.01933 ,   98.50967 ],\n",
    "#        [-354.03867 , -173.01933 ,  370.03867 ,  189.01933 ]],\n",
    "#       dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_size = (800//16)\n",
    "ctr_x = np.arange(16, (fe_size+1) * 16, 16)\n",
    "ctr_y = np.arange(16, (fe_size+1) * 16, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in shift_x:\n",
    "  #for y in shift_y:\n",
    "    #Generate anchors at (x, y) locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = []\n",
    "index = 0\n",
    "for x in range(len(ctr_x)):\n",
    "    for y in range(len(ctr_y)):\n",
    "        point = (ctr_y[y]-8,ctr_x[x]-8)\n",
    "        ctr.append(point)\n",
    "        #ctr[index, 1] = ctr_x[x] - 8\n",
    "        #ctr[index, 0] = ctr_y[y] - 8\n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = fe_size*fe_size*9\n",
    "anchors = np.zeros([length,4])\n",
    "index = 0\n",
    "for c in ctr:\n",
    "  [ctr_y, ctr_x] = c\n",
    "  for i in range(len(ratio)):\n",
    "    for j in range(len(anchor_scales)):\n",
    "      h = sub_sample * anchor_scales[j] * np.sqrt(ratio[i])\n",
    "      w = sub_sample * anchor_scales[j] * np.sqrt(1./ ratio[i])\n",
    "      anchors[index, 0] = ctr_y - h / 2.\n",
    "      anchors[index, 1] = ctr_x - w / 2.\n",
    "      anchors[index, 2] = ctr_y + h / 2.\n",
    "      anchors[index, 3] = ctr_x + w / 2.\n",
    "      index += 1\n",
    "print(anchors.shape)\n",
    "#Out: [22500, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = np.asarray([[20, 30, 400, 500], [300, 400, 500, 600]], dtype=np.float32) # [y1, x1, y2, x2] format\n",
    "labels = np.asarray([6, 8], dtype=np.int8) # 0 represents background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_inside = np.where(\n",
    "        (anchors[:, 0] >= 0) &\n",
    "        (anchors[:, 1] >= 0) &\n",
    "        (anchors[:, 2] <= 800) &\n",
    "        (anchors[:, 3] <= 800)\n",
    "    )[0]\n",
    "print(index_inside.shape)\n",
    "#Out: (8940,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.empty((index_inside.shape), dtype=np.int32)\n",
    "label.fill(-1)\n",
    "print(label.shape)\n",
    "#Out = (8940, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_anchor_boxes = anchors[index_inside]\n",
    "print(valid_anchor_boxes.shape)\n",
    "#Out = (8940, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the max of x1 and y1 in both the boxes (xn1, yn1)\n",
    "- Find the min of x2 and y2 in both the boxes (xn2, yn2)\n",
    "- Now both the boxes are intersecting only\n",
    " if (xn1 < xn2) and (yn2 < yn1)\n",
    "      - iou_area will be (xn2 - xn1) * (yn2 - yn1)\n",
    " else\n",
    "      - iuo_area will be 0\n",
    "- similarly calculate area for anchor box and ground truth object\n",
    "- iou = iou_area/(anchor_box_area + ground_truth_area - iou_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.empty((len(valid_anchor_boxes), 2), dtype=np.float32)\n",
    "ious.fill(0)\n",
    "print(bbox)\n",
    "for num1, i in enumerate(valid_anchor_boxes):\n",
    "    (ya1, xa1, ya2, xa2) = i  \n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    for num2, j in enumerate(bbox):\n",
    "        (yb1, xb1, yb2, xb2) = j\n",
    "        box_area = (yb2- yb1) * (xb2 - xb1)\n",
    "        inter_x1 = max([xb1, xa1])\n",
    "        inter_y1 = max([yb1, ya1])\n",
    "        inter_x2 = min([xb2, xa2])\n",
    "        inter_y2 = min([yb2, ya2])\n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * \\\n",
    "(inter_x2 - inter_x1)\n",
    "            iou = iter_area / \\\n",
    "(anchor_area+ box_area - iter_area)            \n",
    "        else:\n",
    "            iou = 0.\n",
    "        ious[num1, num2] = iou\n",
    "print(ious.shape)\n",
    "#Out: [22500, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_argmax_ious = ious.argmax(axis=0)\n",
    "print(gt_argmax_ious)\n",
    "gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
    "print(gt_max_ious)\n",
    "# Out:\n",
    "# [2262 5620]\n",
    "# [0.68130493 0.61035156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_ious = ious.argmax(axis=1)\n",
    "print(argmax_ious.shape)\n",
    "print(argmax_ious)\n",
    "max_ious = ious[np.arange(len(index_inside)), argmax_ious]\n",
    "print(max_ious)\n",
    "# Out:\n",
    "# (22500,)\n",
    "# [0, 1, 0, ..., 1, 0, 0]\n",
    "# [0.06811669 0.07083762 0.07083762 ... 0.         0.         0.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "print(gt_argmax_ious)\n",
    "# Out:\n",
    "# [2262, 2508, 5620, 5628, 5636, 5644, 5866, 5874, 5882, 5890, 6112,\n",
    "#        6120, 6128, 6136, 6358, 6366, 6374, 6382]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_iou_threshold  = 0.7\n",
    "neg_iou_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[max_ious < neg_iou_threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[gt_argmax_ious] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[max_ious >= pos_iou_threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ratio = 0.5\n",
    "n_sample = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos = pos_ratio * n_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.where(label == 1)[0]\n",
    "if len(pos_index) > n_pos:\n",
    "    disable_index = np.random.choice(pos_index, size=(len(pos_index) - n_pos), replace=False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neg = n_sample * np.sum(label == 1)\n",
    "neg_index = np.where(label == 0)[0]\n",
    "if len(neg_index) > n_neg:\n",
    "    disable_index = np.random.choice(neg_index, size=(len(neg_index) - n_neg), replace = False)\n",
    "    label[disable_index] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_{x} = (x - x_{a})/w_{a}\n",
    "#t_{y} = (y - y_{a})/h_{a}\n",
    "#t_{w} = log(w/ w_a)\n",
    "#t_{h} = log(h/ h_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iou_bbox = bbox[argmax_ious]\n",
    "print(max_iou_bbox)\n",
    "#Out\n",
    "# [[ 20.,  30., 400., 500.],\n",
    "#  [ 20.,  30., 400., 500.],\n",
    "#  [ 20.,  30., 400., 500.],\n",
    "#  ...,\n",
    "#  [ 20.,  30., 400., 500.],\n",
    "#  [ 20.,  30., 400., 500.],\n",
    "#  [ 20.,  30., 400., 500.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = valid_anchor_boxes[:, 2] - valid_anchor_boxes[:, 0]\n",
    "width = valid_anchor_boxes[:, 3] - valid_anchor_boxes[:, 1]\n",
    "ctr_y = valid_anchor_boxes[:, 0] + 0.5 * height\n",
    "ctr_x = valid_anchor_boxes[:, 1] + 0.5 * width\n",
    "base_height = max_iou_bbox[:, 2] - max_iou_bbox[:, 0]\n",
    "base_width = max_iou_bbox[:, 3] - max_iou_bbox[:, 1]\n",
    "base_ctr_y = max_iou_bbox[:, 0] + 0.5 * base_height\n",
    "base_ctr_x = max_iou_bbox[:, 1] + 0.5 * base_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)\n",
    "anchor_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "print(anchor_locs)\n",
    "#Out:\n",
    "# [[ 0.5855727   2.3091455   0.7415673   1.647276  ]\n",
    "#  [ 0.49718437  2.3091455   0.7415673   1.647276  ]\n",
    "#  [ 0.40879607  2.3091455   0.7415673   1.647276  ]\n",
    "#  ...\n",
    "#  [-2.50802    -5.292254    0.7415677   1.6472763 ]\n",
    "#  [-2.5964084  -5.292254    0.7415677   1.6472763 ]\n",
    "#  [-2.6847968  -5.292254    0.7415677   1.6472763 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_labels = np.empty((len(anchors),), dtype=label.dtype)\n",
    "anchor_labels.fill(-1)\n",
    "anchor_labels[index_inside] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_locations = np.empty((len(anchors),) + anchors.shape[1:], dtype=anchor_locs.dtype)\n",
    "anchor_locations.fill(0)\n",
    "anchor_locations[index_inside, :] = anchor_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Region Proposal Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "mid_channels = 512\n",
    "in_channels = 512 # depends on the output feature map. in vgg 16 it is equal to 512\n",
    "n_anchor = 9 # Number of anchors at each location\n",
    "conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "reg_layer = nn.Conv2d(mid_channels, n_anchor *4, 1, 1, 0)\n",
    "cls_layer = nn.Conv2d(mid_channels, n_anchor *2, 1, 1, 0) ## I will be going to use softmax here. you can equally use sigmoid if u replace 2 with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv sliding layer\n",
    "conv1.weight.data.normal_(0, 0.01)\n",
    "conv1.bias.data.zero_()\n",
    "# Regression layer\n",
    "reg_layer.weight.data.normal_(0, 0.01)\n",
    "reg_layer.bias.data.zero_()\n",
    "# classification layer\n",
    "cls_layer.weight.data.normal_(0, 0.01)\n",
    "cls_layer.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv1(out_map) # out_map is obtained in section 1\n",
    "pred_anchor_locs = reg_layer(x)\n",
    "pred_cls_scores = cls_layer(x)\n",
    "print(pred_cls_scores.shape, pred_anchor_locs.shape)\n",
    "#Out:\n",
    "#torch.Size([1, 18, 50, 50]) torch.Size([1, 36, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anchor_locs = pred_anchor_locs.permute(0, 2, 3, 1).contiguous().view(1, -1, 4)\n",
    "print(pred_anchor_locs.shape)\n",
    "#Out: torch.Size([1, 22500, 4])\n",
    "pred_cls_scores = pred_cls_scores.permute(0, 2, 3, 1).contiguous()\n",
    "print(pred_cls_scores.shape)\n",
    "#Out torch.Size([1, 50, 50, 18])\n",
    "\n",
    "objectness_score = pred_cls_scores.view(1, 50, 50, 9, 2)[:, :, :, :, 1].contiguous().view(1, -1)\n",
    "print(objectness_score.shape)\n",
    "#Out torch.Size([1, 22500])\n",
    "pred_cls_scores  = pred_cls_scores.view(1, -1, 2)\n",
    "print(pred_cls_scores.shape)\n",
    "# Out torch.size([1, 22500, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_thresh = 0.7\n",
    "n_train_pre_nms = 12000\n",
    "n_train_post_nms = 2000\n",
    "n_test_pre_nms = 6000\n",
    "n_test_post_nms = 300\n",
    "min_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = (w_{a} * ctr_x_{p}) + ctr_x_{a}\n",
    "y = (h_{a} * ctr_x_{p}) + ctr_x_{a}\n",
    "h = np.exp(h_{p}) * h_{a}\n",
    "w = np.exp(w_{p}) * w_{a}\n",
    "and later convert to y1, x1, y2, x2 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_height = anchors[:, 2] - anchors[:, 0]\n",
    "anc_width = anchors[:, 3] - anchors[:, 1]\n",
    "anc_ctr_y = anchors[:, 0] + 0.5 * anc_height\n",
    "anc_ctr_x = anchors[:, 1] + 0.5 * anc_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_anchor_locs_numpy = pred_anchor_locs[0].data.numpy()\n",
    "objectness_score_numpy = objectness_score[0].data.numpy()\n",
    "dy = pred_anchor_locs_numpy[:, 0::4]\n",
    "dx = pred_anchor_locs_numpy[:, 1::4]\n",
    "dh = pred_anchor_locs_numpy[:, 2::4]\n",
    "dw = pred_anchor_locs_numpy[:, 3::4]\n",
    "ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]\n",
    "ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]\n",
    "h = np.exp(dh) * anc_height[:, np.newaxis]\n",
    "w = np.exp(dw) * anc_width[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype=pred_anchor_locs_numpy.dtype)\n",
    "roi[:, 0::4] = ctr_y - 0.5 * h\n",
    "roi[:, 1::4] = ctr_x - 0.5 * w\n",
    "roi[:, 2::4] = ctr_y + 0.5 * h\n",
    "roi[:, 3::4] = ctr_x + 0.5 * w\n",
    "\n",
    "print(ctr_y)\n",
    "print(h)\n",
    "\n",
    "print(roi)\n",
    "#Out:\n",
    "# [[ -36.897102,  -80.29519 ,   54.09939 ,  100.40507 ],\n",
    "#  [ -83.12463 , -165.74298 ,   98.67854 ,  188.6116  ],\n",
    "#  [-170.7821  , -378.22214 ,  196.20844 ,  349.81198 ],\n",
    "#  ...,\n",
    "#  [ 696.17816 ,  747.13306 ,  883.4582  ,  836.77747 ],\n",
    "#  [ 621.42114 ,  703.0614  ,  973.04626 ,  885.31226 ],\n",
    "#  [ 432.86267 ,  622.48926 , 1146.7059  ,  982.9209  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (800, 800) #Image size\n",
    "roi[:, slice(0, 4, 2)] = np.clip(\n",
    "            roi[:, slice(0, 4, 2)], 0, img_size[0])\n",
    "roi[:, slice(1, 4, 2)] = np.clip(\n",
    "    roi[:, slice(1, 4, 2)], 0, img_size[1])\n",
    "print(roi)\n",
    "#Out:\n",
    "# [[  0.     ,   0.     ,  54.09939, 100.40507],\n",
    "#  [  0.     ,   0.     ,  98.67854, 188.6116 ],\n",
    "#  [  0.     ,   0.     , 196.20844, 349.81198],\n",
    "#  ...,\n",
    "#  [696.17816, 747.13306, 800.     , 800.     ],\n",
    "#  [621.42114, 703.0614 , 800.     , 800.     ],\n",
    "#  [432.86267, 622.48926, 800.     , 800.     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs = roi[:, 2] - roi[:, 0]\n",
    "ws = roi[:, 3] - roi[:, 1]\n",
    "keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "roi = roi[keep, :]\n",
    "score = objectness_score_numpy[keep]\n",
    "print(score.shape)\n",
    "#Out:\n",
    "##(22500, ) all the boxes have minimum size of 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = score.ravel().argsort()[::-1]\n",
    "print(order)\n",
    "#Out:\n",
    "#[ 889,  929, 1316, ...,  462,  454,    4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = order[:n_train_pre_nms]\n",
    "roi = roi[order, :]\n",
    "print(roi.shape)\n",
    "print(roi)\n",
    "#Out\n",
    "# (12000, 4)\n",
    "# [[607.93866,   0.     , 800.     , 113.38187],\n",
    "#  [  0.     ,   0.     , 235.29704, 369.64795],\n",
    "#  [572.177  ,   0.     , 800.     , 373.0086 ],\n",
    "#  ...,\n",
    "#  [250.07968, 186.61633, 434.6356 , 276.70615],\n",
    "#  [490.07974, 154.6163 , 674.6356 , 244.70615],\n",
    "#  [266.07968, 602.61633, 450.6356 , 692.7062 ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take all the roi boxes [roi_array]\n",
    "- Find the areas of all the boxes [roi_area]\n",
    "- Take the indexes of order the probability score in descending order [order_array]\n",
    "keep = []\n",
    "while order_array.size > 0:\n",
    "  - take the first element in order_array and append that to keep  \n",
    "  - Find the area with all other boxes\n",
    "  - Find the index of all the boxes which have high overlap with this box\n",
    "  - Remove them from order array\n",
    "  - Iterate this till we get the order_size to zero (while loop)\n",
    "- Ouput the keep variable which tells what indexes to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = roi[:, 0]\n",
    "x1 = roi[:, 1]\n",
    "y2 = roi[:, 2]\n",
    "x2 = roi[:, 3]\n",
    "area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "print(area.shape)\n",
    "print(order.shape)\n",
    "order = order.argsort()[::-1]\n",
    "keep = []\n",
    "while order.size > 0:\n",
    "    i = order[0]\n",
    "    xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "    yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "    xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "    yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "    w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "    inter = w * h\n",
    "    ovr = inter / (area[i] + area[order[1:]] - inter)\n",
    "    inds = np.where(ovr <= nms_thresh)[0]\n",
    "    order = order[inds + 1]\n",
    "    keep.append(i)\n",
    "print(len(keep))\n",
    "keep = keep[:n_train_post_nms] # while training/testing , use accordingly\n",
    "roi = roi[keep] # the final region proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 128\n",
    "pos_ratio = 0.25\n",
    "pos_iou_thresh = 0.5\n",
    "neg_iou_thresh_hi = 0.5\n",
    "neg_iou_thresh_lo = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each roi, find the IoU with all other ground truth object [N, n]\n",
    "    - where N is the number of region proposal boxes\n",
    "    - n is the number of ground truth boxes\n",
    "- Find which ground truth object has highest iou with the roi [N], these are the labels for each and every region proposal\n",
    "- If the highest IoU is greater than pos_iou_thesh[0.5], then we assign the label.\n",
    "- pos_samples:\n",
    "      - We randomly samply [n_sample x pos_ratio] region proposals and consider these only as positive labels\n",
    "- If the IoU is between [0.1, 0.5], we assign a negitive label[0] to the region proposal\n",
    "- neg_samples:\n",
    "      - We randomly sample [128- number of pos region proposals on this image] and assign 0 to these region proposals\n",
    "- We collect the pos_samples and neg_samples  and remove all other region proposals\n",
    "- convert the locations of groundtruth objects for each region proposal to the required format (Described in Fast R-CNN)\n",
    "- Ouput labels and locations for the sampled_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.empty((len(roi), 2), dtype=np.float32)\n",
    "ious.fill(0)\n",
    "print(ious.shape)\n",
    "print(roi)\n",
    "print(bbox)\n",
    "for num1, i in enumerate(roi):\n",
    "    ya1, xa1, ya2, xa2 = i  \n",
    "    anchor_area = (ya2 - ya1) * (xa2 - xa1)\n",
    "    for num2, j in enumerate(bbox):\n",
    "        yb1, xb1, yb2, xb2 = j\n",
    "        box_area = (yb2- yb1) * (xb2 - xb1)\n",
    "        inter_x1 = max([xb1, xa1])\n",
    "        inter_y1 = max([yb1, ya1])\n",
    "        inter_x2 = min([xb2, xa2])\n",
    "        inter_y2 = min([yb2, ya2])\n",
    "        if (inter_x1 < inter_x2) and (inter_y1 < inter_y2):\n",
    "            iter_area = (inter_y2 - inter_y1) * \\\n",
    "(inter_x2 - inter_x1)\n",
    "            iou = iter_area / (anchor_area+ \\\n",
    "box_area - iter_area)            \n",
    "        else:\n",
    "            iou = 0.\n",
    "        ious[num1, num2] = iou\n",
    "print(ious.shape)\n",
    "#Out:\n",
    "#[1535, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_assignment = ious.argmax(axis=1)\n",
    "max_iou = ious.max(axis=1)\n",
    "print(gt_assignment)\n",
    "print(max_iou)\n",
    "#Out:\n",
    "# [0, 0, 0 ... 1, 1, 0]\n",
    "# [0.016, 0., 0. ... 0.08034518, 0.10739268, 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_roi_label = labels[gt_assignment]\n",
    "print(gt_roi_label)\n",
    "#Out:\n",
    "#[6, 6, 6, ..., 8, 8, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.where(max_iou >= pos_iou_thresh)[0]\n",
    "pos_roi_per_image = 32\n",
    "pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
    "if pos_index.size > 0:\n",
    "    pos_index = np.random.choice(\n",
    "        pos_index, size=pos_roi_per_this_image, replace=False)\n",
    "print(pos_roi_per_this_image)\n",
    "print(pos_index)\n",
    "#Out\n",
    "# 18\n",
    "# [ 257  296  317 1075 1077 1169 1213 1258 1322 1325 1351 1378 1380 1425\n",
    "#  1472 1482 1489 1495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_index = np.where((max_iou < neg_iou_thresh_hi) &\n",
    "                             (max_iou >= neg_iou_thresh_lo))[0]\n",
    "neg_roi_per_this_image = n_sample - pos_roi_per_this_image\n",
    "neg_roi_per_this_image = int(min(neg_roi_per_this_image,\n",
    "                                 neg_index.size))\n",
    "if  neg_index.size > 0 :\n",
    "    neg_index = np.random.choice(\n",
    "        neg_index, size=neg_roi_per_this_image, replace=False)\n",
    "print(neg_roi_per_this_image)\n",
    "print(neg_index)\n",
    "#Out:\n",
    "#110\n",
    "# [  79  688  160  ...  376  712 1235  148 1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_index = np.append(pos_index, neg_index)\n",
    "gt_roi_labels = gt_roi_label[keep_index]\n",
    "gt_roi_labels[pos_roi_per_this_image:] = 0  # negative labels --> 0\n",
    "sample_roi = roi[keep_index]\n",
    "print(sample_roi.shape)\n",
    "#Out:\n",
    "#(128, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_for_sampled_roi = bbox[gt_assignment[keep_index]]\n",
    "print(bbox_for_sampled_roi.shape)\n",
    "#Out\n",
    "#(128, 4)\n",
    "height = sample_roi[:, 2] - sample_roi[:, 0]\n",
    "width = sample_roi[:, 3] - sample_roi[:, 1]\n",
    "ctr_y = sample_roi[:, 0] + 0.5 * height\n",
    "ctr_x = sample_roi[:, 1] + 0.5 * width\n",
    "base_height = bbox_for_sampled_roi[:, 2] - bbox_for_sampled_roi[:, 0]\n",
    "base_width = bbox_for_sampled_roi[:, 3] - bbox_for_sampled_roi[:, 1]\n",
    "base_ctr_y = bbox_for_sampled_roi[:, 0] + 0.5 * base_height\n",
    "base_ctr_x = bbox_for_sampled_roi[:, 1] + 0.5 * base_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_{x} = (x - x_{a})/w_{a}\n",
    "#t_{y} = (y - y_{a})/h_{a}\n",
    "#t_{w} = log(w/ w_a)\n",
    "#t_{h} = log(h/ h_a)\n",
    "eps = np.finfo(height.dtype).eps\n",
    "height = np.maximum(height, eps)\n",
    "width = np.maximum(width, eps)\n",
    "dy = (base_ctr_y - ctr_y) / height\n",
    "dx = (base_ctr_x - ctr_x) / width\n",
    "dh = np.log(base_height / height)\n",
    "dw = np.log(base_width / width)\n",
    "gt_roi_locs = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "print(gt_roi_locs)\n",
    "#Out:\n",
    "# [[-0.08075945, -0.14638858, -0.23822695, -0.23150307],\n",
    "#  [ 0.04865225,  0.15570255,  0.08902431, -0.5969549 ],\n",
    "#  [ 0.17411101,  0.2244332 ,  0.19870323,  0.25063717],\n",
    "#  .....\n",
    "#  [-0.13976236,  0.121031  ,  0.03863466,  0.09662855],\n",
    "#  [-0.59361845, -2.5121436 ,  0.04558792,  0.9731178 ],\n",
    "#  [ 0.1041566 , -0.7840459 ,  1.4283055 ,  0.95092565]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roi = np.zeros(pred_anchor_locs_numpy.shape, dtype=anchor_locs.dtype)\n",
    "print(ctr_y)\n",
    "print(h.size)\n",
    "roi[:, 0::4] = ctr_y - 0.5 * h\n",
    "roi[:, 1::4] = ctr_x - 0.5 * w\n",
    "roi[:, 2::4] = ctr_y + 0.5 * h\n",
    "roi[:, 3::4] = ctr_x + 0.5 * w\n",
    "#Out:\n",
    "# [[ -36.897102,  -80.29519 ,   54.09939 ,  100.40507 ],\n",
    "#  [ -83.12463 , -165.74298 ,   98.67854 ,  188.6116  ],\n",
    "#  [-170.7821  , -378.22214 ,  196.20844 ,  349.81198 ],\n",
    "#  ...,\n",
    "#  [ 696.17816 ,  747.13306 ,  883.4582  ,  836.77747 ],\n",
    "#  [ 621.42114 ,  703.0614  ,  973.04626 ,  885.31226 ],\n",
    "#  [ 432.86267 ,  622.48926 , 1146.7059  ,  982.9209  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = torch.from_numpy(sample_rois).float()\n",
    "roi_indices = 0 * np.ones((len(rois),), dtype=np.int32)\n",
    "roi_indices = torch.from_numpy(roi_indices).float()\n",
    "print(rois.shape, roi_indices.shape)\n",
    "#Out:\n",
    "#torch.Size([128, 4]) torch.Size([128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_and_rois = torch.cat([roi_indices[:, None], rois], dim=1)\n",
    "xy_indices_and_rois = indices_and_rois[:, [0, 2, 1, 4, 3]]\n",
    "indices_and_rois = xy_indices_and_rois.contiguous()\n",
    "print(xy_indices_and_rois.shape)\n",
    "#Out:\n",
    "#torch.Size([128, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multiply the dimensions of rois with the sub_sampling ratio (16 in this case)\n",
    "- Empty output Tensor\n",
    "- Take each roi\n",
    "    - subset the feature map based on the roi dimension\n",
    "    - Apply AdaptiveMaxPool2d to this subset Tensor.\n",
    "    - Add the outputs to the output Tensor\n",
    "- Empty output Tensor goes to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (7, 7)\n",
    "adaptive_max_pool = AdaptiveMaxPool2d(size[0], size[1])\n",
    "output = []\n",
    "rois = indices_and_rois.data.float()\n",
    "rois[:, 1:].mul_(1/16.0) # Subsampling ratio\n",
    "rois = rois.long()\n",
    "num_rois = rois.size(0)\n",
    "for i in range(num_rois):\n",
    "    roi = rois[i]\n",
    "    im_idx = roi[0]\n",
    "    im = out_map.narrow(0, im_idx, 1)[..., roi[2]:(roi[4]+1), roi[1]:(roi[3]+1)]\n",
    "    output.append(adaptive_max_pool(im))\n",
    "output = torch.cat(output, 0)\n",
    "print(output.size())\n",
    "#Out:\n",
    "# torch.Size([128, 512, 7, 7])\n",
    "# Reshape the tensor so that we can pass it through the feed forward layer.\n",
    "k = output.view(output.size(0), -1)\n",
    "print(k.shape)\n",
    "#Out:\n",
    "# torch.Size([128, 25088])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_head_classifier = nn.Sequential(*[nn.Linear(25088, 4096),\n",
    "                                      nn.Linear(4096, 4096)])\n",
    "cls_loc = nn.Linear(4096, 21 * 4) # (VOC 20 classes + 1 background. Each will have 4 co-ordinates)\n",
    "cls_loc.weight.data.normal_(0, 0.01)\n",
    "cls_loc.bias.data.zero_()\n",
    "\n",
    "score = nn.Linear(4096, 21) # (VOC 20 classes + 1 background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = roi_head_classifier(k)\n",
    "roi_cls_loc = cls_loc(k)\n",
    "roi_cls_score = score(k)\n",
    "print(roi_cls_loc.shape, roi_cls_score.shape)\n",
    "#Out:\n",
    "# torch.Size([128, 84]), torch.Size([128, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_anchor_locs.shape)\n",
    "print(pred_cls_scores.shape)\n",
    "print(anchor_locations.shape)\n",
    "print(anchor_labels.shape)\n",
    "#Out:\n",
    "# torch.Size([1, 12321, 4])\n",
    "# torch.Size([1, 12321, 2])\n",
    "# (12321, 4)\n",
    "# (12321,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_loc = pred_anchor_locs[0]\n",
    "rpn_score = pred_cls_scores[0]\n",
    "gt_rpn_loc = torch.from_numpy(anchor_locations)\n",
    "gt_rpn_score = torch.from_numpy(anchor_labels)\n",
    "print(rpn_loc.shape, rpn_score.shape, gt_rpn_loc.shape, gt_rpn_score.shape)\n",
    "#Out\n",
    "# torch.Size([12321, 4]) torch.Size([12321, 2]) torch.Size([12321, 4]) torch.Size([12321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_score.long(), ignore_index = -1)\n",
    "print(rpn_cls_loss)\n",
    "#Out:\n",
    "# Variable containing:\n",
    "#  0.6940\n",
    "# [torch.FloatTensor of size 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = gt_rpn_score > 0\n",
    "mask = pos.unsqueeze(1).expand_as(rpn_loc)\n",
    "print(mask.shape)\n",
    "#Out:\n",
    "# torch.Size(12321, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_loc_preds = rpn_loc[mask].view(-1, 4)\n",
    "mask_loc_targets = gt_rpn_loc[mask].view(-1, 4)\n",
    "print(mask_loc_preds.shape, mask_loc_preds.shape)\n",
    "#Out:\n",
    "# torch.Size([6, 4]) torch.Size([6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.abs(mask_loc_targets - mask_loc_preds)\n",
    "rpn_loc_loss = ((x < 1).float() * 0.5 * x**2) + ((x >= 1).float() * (x-0.5))\n",
    "print(rpn_loc_loss.sum())\n",
    "#Out:\n",
    "# Variable containing:\n",
    "#  0.3826\n",
    "# [torch.FloatTensor of size 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_lambda = 10.\n",
    "N_reg = (gt_rpn_score >0).float().sum()\n",
    "rpn_loc_loss = rpn_loc_loss.sum() / N_reg\n",
    "rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)\n",
    "print(rpn_loss)\n",
    "#Out:0.00248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fast R-CNN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roi_cls_loc.shape)\n",
    "print(roi_cls_score.shape)\n",
    "#Out:\n",
    "# torch.Size([128, 84])\n",
    "# torch.Size([128, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_roi_locs.shape)\n",
    "print(gt_roi_labels.shape)\n",
    "#Out:\n",
    "#(128, 4)\n",
    "#(128, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_roi_loc = torch.from_numpy(gt_roi_locs)\n",
    "gt_roi_label = torch.from_numpy(np.float32(gt_roi_labels)).long()\n",
    "print(gt_roi_loc.shape, gt_roi_label.shape)\n",
    "#Out:\n",
    "#torch.Size([128, 4]) torch.Size([128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_clss_loss = F.cross_entropy(roi_cls_score, rt_roi_label, ignore_index=-1)\n",
    "print(roi_cls_loss.shape)\n",
    "#Out:\n",
    "#Variable containing:\n",
    "#  3.0458\n",
    "# [torch.FloatTensor of size 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = roi_cls_loc.shape[0]\n",
    "roi_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
    "print(roi_loc.shape)\n",
    "#Out:\n",
    "#torch.Size([128, 21, 4])\n",
    "roi_loc = roi_loc[torch.arange(0, n_sample).long(), gt_roi_label]\n",
    "print(roi_loc.shape)\n",
    "#Out:\n",
    "#torch.Size([128, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_loc_loss = REGLoss(roi_loc, gt_roi_loc)\n",
    "print(roi_loc_loss)\n",
    "#Out:\n",
    "#Variable containing:\n",
    "#  0.1895\n",
    "# [torch.FloatTensor of size 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_lambda = 10.\n",
    "roi_loss = roi_cls_loss + (roi_lambda * roi_loc_loss)\n",
    "print(roi_loss)\n",
    "#Out:\n",
    "#Variable containing:\n",
    "#  4.2353\n",
    "# [torch.FloatTensor of size 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = rpn_loss + roi_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
